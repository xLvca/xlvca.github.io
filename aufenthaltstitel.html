<!DOCTYPE html>
<html lang="de">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"/>
<title>Robuster DE Ausweis / Aufenthaltstitel Scanner</title>
<style>
  :root{
    --bg:#0c0f12;--card:#131516;--accent:#0abfdf;--muted:#9aa6ad;--good:#7be28b;
  }
  *{box-sizing:border-box}
  body{margin:0;background:var(--bg);color:#e6eef1;font-family:Inter,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;display:flex;flex-direction:column;align-items:center;min-height:100vh;padding:12px;}
  header{width:100%;max-width:480px;text-align:center;padding:14px 8px;border-radius:10px;color:var(--accent);font-weight:700}
  .frame{width:100%;max-width:480px}
  #videoContainer{position:relative;border-radius:12px;overflow:hidden;background:#000;height:calc(100vw*0.75);max-height:62vh}
  video{width:100%;height:100%;object-fit:cover;transform-origin:center center}
  #overlay{position:absolute;left:50%;top:50%;transform:translate(-50%,-50%);pointer-events:none;border:2px solid rgba(10,191,223,0.95);border-radius:12px;box-shadow:inset 0 0 8px rgba(10,191,223,0.12);width:84%;height:48%}
  .controls{display:flex;gap:8px;margin-top:10px;width:100%;max-width:480px;flex-wrap:wrap}
  select,button{flex:1;min-width:110px;padding:10px;border-radius:10px;border:none;background:var(--card);color:#e6eef1;font-weight:600}
  #scanBtn{background:linear-gradient(90deg,var(--accent),#08a0c0);color:#071018}
  #status{margin-top:8px;color:var(--muted);font-weight:600;text-align:center;min-height:20px}
  #result{margin-top:10px;background:#0f1416;padding:12px;border-radius:10px;width:100%;max-width:480px;color:#dfeff2;white-space:pre-wrap;font-family:monospace;max-height:220px;overflow:auto}
  .small{font-size:0.9rem;color:var(--muted)}
  @media(max-width:420px){#videoContainer{height:62vh}}
</style>
</head>
<body>
  <header>Robuster DE Ausweis & Aufenthaltstitel Scanner — lokal</header>
  <div class="frame">
    <div id="videoContainer">
      <video id="video" autoplay playsinline muted></video>
      <div id="overlay" aria-hidden="true"></div>
    </div>

    <div class="controls">
      <select id="doctype" title="Dokument wählen">
        <option value="aufenth">Aufenthaltstitel</option>
        <option value="pa">Personalausweis</option>
      </select>
      <select id="side" title="Seite wählen">
        <option value="front">Vorderseite</option>
        <option value="back">Rückseite</option>
      </select>
      <button id="scanBtn">Start Scan</button>
    </div>

    <div style="display:flex;gap:8px;margin-top:8px;justify-content:center;">
      <button id="flash" class="small">⚡ Blitz</button>
      <div id="status">Bitte Dokument ins Overlay legen. Gute Beleuchtung hilft.</div>
    </div>

    <pre id="result" aria-live="polite"></pre>
  </div>

<!-- OpenCV.js (async load) -->
<script async src="https://docs.opencv.org/4.x/opencv.js" onload="console.log('OpenCV geladen')"></script>
<!-- Tesseract.js -->
<script src="https://cdn.jsdelivr.net/npm/tesseract.js@4.1.1/dist/tesseract.min.js"></script>

<script>
(async ()=>{

// ---- Globals & elements ----
const video = document.getElementById('video');
const overlay = document.getElementById('overlay');
const scanBtn = document.getElementById('scanBtn');
const statusEl = document.getElementById('status');
const resultEl = document.getElementById('result');
const doctypeSel = document.getElementById('doctype');
const sideSel = document.getElementById('side');
const flashBtn = document.getElementById('flash');

let stream = null, track = null;
let worker = null;
let isProcessing = false;

// Auto-capture stability buffer
let prevGray = null;
let stableFrames = 0;
const STABLE_THRESHOLD = 6; // frames needed stable
const DIFF_LIMIT = 60; // low -> stable

// ---- Start camera ----
async function startCamera(){
  status('Kamera wird gestartet...');
  try {
    stream = await navigator.mediaDevices.getUserMedia({
      video: { facingMode:'environment', width:{ideal:1280}, height:{ideal:720} },
      audio: false
    });
    video.srcObject = stream;
    track = stream.getVideoTracks()[0];
    await new Promise(r => video.onloadedmetadata = r);
    status('Kamera bereit — Overlay benutzen, um das Dokument auszurichten.');
    // enable flash button only if torch capability present
    if(track.getCapabilities && track.getCapabilities().torch) flashBtn.style.display = 'inline-block';
    else flashBtn.style.display = 'none';
  } catch(e){
    status('Kamera konnte nicht gestartet werden: ' + e.message);
    flashBtn.style.display = 'none';
  }
}

// ---- Tesseract worker init once ----
async function initWorker(){
  if(worker) return;
  status('Tesseract lädt (einmalig, kann einige Sekunden dauern)...');
  worker = await Tesseract.createWorker({
    logger: m => {
      if(m.status==='recognizing text') status(`OCR: ${(m.progress*100).toFixed(0)}%`);
    }
  });
  await worker.load();
  await worker.loadLanguage('deu');
  await worker.initialize('deu');
  // set some params for speed/accuracy
  await worker.setParameters({
    tessedit_char_whitelist: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyzÄÖÜäöüß0123456789<>.:-/ ',
    preserve_interword_spaces: '1'
  });
  status('OCR bereit.');
}

// ---- Utility: status ----
function status(s){ statusEl.textContent = s; }

// ---- Capture helpers ----
function getOverlayCropRect(){
  // returns crop rectangle in video pixels
  const vRect = video.getBoundingClientRect();
  const oRect = overlay.getBoundingClientRect();
  const scaleX = video.videoWidth / vRect.width;
  const scaleY = video.videoHeight / vRect.height;
  const x = Math.max(0, Math.floor((oRect.left - vRect.left) * scaleX));
  const y = Math.max(0, Math.floor((oRect.top - vRect.top) * scaleY));
  const w = Math.min(video.videoWidth, Math.floor(oRect.width * scaleX));
  const h = Math.min(video.videoHeight, Math.floor(oRect.height * scaleY));
  return {x,y,w,h};
}

function drawToCanvasFromVideo(c, sx,sy,sw,sh){
  const ctx = c.getContext('2d');
  ctx.drawImage(video, sx, sy, sw, sh, 0,0, c.width, c.height);
}

// ---- OpenCV document detection & warp ----
function findDocumentAndWarp(srcCanvas){
  try{
    if (typeof cv === 'undefined') return null;
    let src = cv.imread(srcCanvas);
    let orig = src.clone();
    // convert to gray, blur, edge detect
    cv.cvtColor(src, src, cv.COLOR_RGBA2GRAY);
    cv.bilateralFilter(src, src, 9, 75, 75);
    cv.Canny(src, src, 50, 150);
    // dilate to close gaps
    let M = cv.Mat.ones(5,5, cv.CV_8U);
    cv.dilate(src, src, M);
    // find contours
    let contours = new cv.MatVector();
    let hierarchy = new cv.Mat();
    cv.findContours(src, contours, hierarchy, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE);
    let maxArea = 0, maxCnt = null;
    for(let i=0;i<contours.size();i++){
      const cnt = contours.get(i);
      const area = cv.contourArea(cnt);
      if(area > maxArea){
        // approx poly
        const peri = cv.arcLength(cnt, true);
        const approx = new cv.Mat();
        cv.approxPolyDP(cnt, approx, 0.02 * peri, true);
        if(approx.rows === 4 && area > 10000){ maxArea = area; maxCnt = approx; }
        approx.delete();
      }
      cnt.delete();
    }
    let warpedCanvas = null;
    if(maxCnt){
      // sort corners (tl,tr,br,bl)
      let pts = [];
      for(let i=0;i<4;i++){
        pts.push({x: maxCnt.intPtr(i,0)[0], y: maxCnt.intPtr(i,0)[1]});
      }
      // order points by sum/diff
      pts.sort((a,b)=>a.x+a.y - (b.x+b.y));
      let tl = pts[0], br = pts[3];
      let rest = [pts[1], pts[2]];
      let tr = rest[0].x < rest[1].x ? rest[0] : rest[1];
      let bl = rest[0].x < rest[1].x ? rest[1] : rest[0];
      // compute width/height
      const widthA = Math.hypot(br.x - bl.x, br.y - bl.y);
      const widthB = Math.hypot(tr.x - tl.x, tr.y - tl.y);
      const maxW = Math.max(widthA, widthB);
      const heightA = Math.hypot(tr.x - br.x, tr.y - br.y);
      const heightB = Math.hypot(tl.x - bl.x, tl.y - bl.y);
      const maxH = Math.max(heightA, heightB);
      // srcPts, dstPts
      let srcTri = cv.matFromArray(4,1,cv.CV_32FC2,[tl.x,tl.y,tr.x,tr.y,br.x,br.y,bl.x,bl.y]);
      let dstTri = cv.matFromArray(4,1,cv.CV_32FC2,[0,0, maxW-1,0, maxW-1,maxH-1, 0,maxH-1]);
      let M_persp = cv.getPerspectiveTransform(srcTri, dstTri);
      let dst = new cv.Mat();
      cv.warpPerspective(orig, dst, M_persp, new cv.Size(Math.floor(maxW), Math.floor(maxH)));
      // output to canvas
      warpedCanvas = document.createElement('canvas');
      warpedCanvas.width = dst.cols; warpedCanvas.height = dst.rows;
      cv.imshow(warpedCanvas, dst);
      // cleanup
      dst.delete(); M_persp.delete(); srcTri.delete(); dstTri.delete();
    }
    contours.delete(); hierarchy.delete(); src.delete(); orig.delete();
    if(maxCnt) maxCnt.delete();
    return warpedCanvas;
  }catch(e){
    console.warn('OpenCV error', e);
    return null;
  }
}

// ---- Preprocess for OCR (grayscale, resize, adaptive threshold) ----
function preprocessForOCR(canvas, targetWidth=1200){
  // scale up for small text
  const scale = Math.max(1, targetWidth / canvas.width);
  const tmp = document.createElement('canvas');
  tmp.width = Math.floor(canvas.width * scale);
  tmp.height = Math.floor(canvas.height * scale);
  const ctx = tmp.getContext('2d');
  ctx.drawImage(canvas,0,0,tmp.width,tmp.height);
  // convert contrast & sharpen (simple unsharp)
  let img = ctx.getImageData(0,0,tmp.width,tmp.height);
  for(let i=0;i<img.data.length;i+=4){
    for(let c=0;c<3;c++){
      let v = img.data[i+c];
      v = ((v-128)*1.15)+128; // slight contrast
      img.data[i+c] = Math.min(255, Math.max(0, Math.round(v)));
    }
  }
  ctx.putImageData(img,0,0);
  // convert to gray & adaptive binarization via canvas (simple)
  const gray = document.createElement('canvas'); gray.width = tmp.width; gray.height = tmp.height;
  const gctx = gray.getContext('2d');
  const im = ctx.getImageData(0,0,tmp.width,tmp.height);
  const id = gctx.createImageData(tmp.width,tmp.height);
  for(let i=0;i<im.data.length;i+=4){
    const r=im.data[i], g=im.data[i+1], b=im.data[i+2];
    const l = Math.round(0.299*r + 0.587*g + 0.114*b);
    id.data[i]=id.data[i+1]=id.data[i+2]=l; id.data[i+3]=255;
  }
  gctx.putImageData(id,0,0);
  // simple adaptive threshold (block)
  const block = 35;
  const out = gctx.getImageData(0,0,gray.width,gray.height);
  for(let y=0;y<gray.height;y+=block){
    for(let x=0;x<gray.width;x+=block){
      // local mean
      let sum=0,cnt=0;
      for(let yy=y; yy<Math.min(y+block,gray.height); yy++){
        for(let xx=x; xx<Math.min(x+block,gray.width); xx++){
          const idx = (yy*gray.width+xx)*4;
          sum += id.data[idx];
          cnt++;
        }
      }
      const mean = sum/cnt;
      // threshold
      for(let yy=y; yy<Math.min(y+block,gray.height); yy++){
        for(let xx=x; xx<Math.min(x+block,gray.width); xx++){
          const idx = (yy*gray.width+xx)*4;
          const v = id.data[idx];
          const val = v < mean*0.95 ? 0 : 255; // slightly adaptive
          out.data[idx]=out.data[idx+1]=out.data[idx+2]=val; out.data[idx+3]=255;
        }
      }
    }
  }
  gctx.putImageData(out,0,0);
  return gray;
}

// ---- MRZ detection helper (simple) ----
function detectMRZLines(text){
  const lines = text.split('\n').map(l=>l.trim()).filter(Boolean);
  // MRZ lines often contain many '<'
  const candidates = lines.filter(l => (l.match(/</g)||[]).length >= 2 && /^[A-Z0-9<\s]+$/.test(l.replace(/ /g,'')));
  return candidates.slice(0,3);
}

// ---- MRZ checksum helper (mod10) ----
function mrzChecksum(s){
  const values = c => {
    if(c>='0' && c<='9') return c.charCodeAt(0)-48;
    if(c>='A' && c<='Z') return c.charCodeAt(0)-55;
    if(c === '<') return 0;
    return 0;
  };
  const weights = [7,3,1];
  let sum=0;
  for(let i=0;i<s.length-1;i++){
    sum += values(s[i])*weights[i%3];
  }
  const cd = parseInt(s[s.length-1],10);
  return sum%10 === cd;
}

// ---- Stable auto-capture (compare gray images) ----
function getGrayFromCanvas(canvas){
  const ctx = canvas.getContext('2d');
  const img = ctx.getImageData(0,0,canvas.width,canvas.height);
  const gray = new Uint8ClampedArray(canvas.width*canvas.height);
  for(let i=0,j=0;i<img.data.length;i+=4,j++){
    gray[j] = Math.round(0.299*img.data[i]+0.587*img.data[i+1]+0.114*img.data[i+2]);
  }
  return {w:canvas.width,h:canvas.height,data:gray};
}
function frameDiff(g1,g2){
  if(!g1||!g2 || g1.w!==g2.w||g1.h!==g2.h) return Infinity;
  let sum=0;
  for(let i=0;i<g1.data.length;i++){
    sum += Math.abs(g1.data[i]-g2.data[i]);
  }
  return sum / g1.data.length;
}

// ---- OCR function using persistent worker ----
async function ocrCanvas(canvas, opts={}){
  if(!worker) await initWorker();
  // pass canvas directly to worker.recognize
  // use page segmentation mode 6 (Assume a single block of text)
  await worker.setParameters({'user_defined_dpi':'300'});
  const res = await worker.recognize(canvas, { tessedit_pageseg_mode: '6' });
  return res.data.text;
}

// ---- Main scan flow ----
async function runScan(auto=false){
  if(isProcessing) return;
  isProcessing = true;
  status('Preparing scan...');
  // prepare small canvas for detection (video-size)
  const vW = video.videoWidth, vH = video.videoHeight;
  if(!vW || !vH){ status('Video nicht bereit'); isProcessing=false; return; }

  // get overlay crop
  const {x,y,w,h} = getOverlayCropRect();
  // small canvas of entire video to detect doc edges (faster)
  const detectCanvas = document.createElement('canvas');
  detectCanvas.width = Math.min(800, vW);
  detectCanvas.height = Math.floor(detectCanvas.width * (vH/vW));
  // draw full video scaled onto detectCanvas
  const dctx = detectCanvas.getContext('2d');
  dctx.drawImage(video, 0, 0, vW, vH, 0, 0, detectCanvas.width, detectCanvas.height);

  // run OpenCV doc detect on scaled canvas
  let warped = null;
  try {
    warped = findDocumentAndWarp(detectCanvas);
  } catch(e){ console.warn('findDocumentAndWarp failed',e); warped = null; }

  // if warped found, use it; else fallback to overlay crop from actual video
  let docCanvas;
  if(warped){
    // scale up warped to width ~1200 for OCR
    docCanvas = document.createElement('canvas');
    const scale = Math.min(1600/warped.width, 1600/warped.height);
    docCanvas.width = Math.floor(warped.width * Math.max(1,scale));
    docCanvas.height = Math.floor(warped.height * Math.max(1,scale));
    const c = docCanvas.getContext('2d');
    c.drawImage(warped,0,0,warped.width,warped.height,0,0,docCanvas.width,docCanvas.height);
    warped = null;
  } else {
    // crop exact overlay area from video
    docCanvas = document.createElement('canvas');
    docCanvas.width = w; docCanvas.height = h;
    drawToCanvasFromVideo(docCanvas, x,y,w,h);
  }

  // Preprocess
  const prep = preprocessForOCR(docCanvas, 1400);

  // Stability check — auto-capture only if stable
  const g = getGrayFromCanvas(prep);
  const diff = frameDiff(prevGray, g);
  prevGray = g;
  if(diff < DIFF_LIMIT){
    stableFrames++;
  } else {
    stableFrames = 0;
  }
  if(auto && stableFrames < STABLE_THRESHOLD){
    status(`Bitte ruhig halten... (${stableFrames}/${STABLE_THRESHOLD})`);
    isProcessing=false;
    return;
  }

  status('OCR läuft — bitte warten...');
  // First try: detect MRZ area heuristically (bottom strip) if scanning back
  const docSide = sideSel.value;
  let rawText = '';
  try {
    // Try full doc OCR first
    rawText = await ocrCanvas(prep);
    // If back side, also attempt MRZ-specific crop: bottom 22% area scaled
    let mrzCandidates = [];
    if(docSide === 'back'){
      const c = document.createElement('canvas');
      c.width = prep.width;
      c.height = Math.floor(prep.height * 0.22);
      const ctx = c.getContext('2d');
      ctx.drawImage(prep, 0, prep.height - c.height - 4, prep.width, c.height, 0,0,c.width,c.height);
      const mrzText = await ocrCanvas(prep);
      // fallback MRZ detection using regex
      mrzCandidates = detectMRZLines(rawText).concat(detectMRZLines(mrzText));
    }

    // If not many chars recognized or fields missing, try alternative binarized versions
    if(rawText.length < 60){
      // invert colors and try
      const inv = document.createElement('canvas');
      inv.width = prep.width; inv.height = prep.height;
      const ictx = inv.getContext('2d');
      ictx.fillStyle = 'white'; ictx.fillRect(0,0,inv.width,inv.height);
      ictx.globalCompositeOperation = 'difference';
      ictx.drawImage(prep,0,0);
      const alt = await ocrCanvas(inv);
      if(alt.length > rawText.length) rawText = alt;
    }

  } catch(e){
    status('OCR Fehler: ' + e.message);
  }

  // Parse extracted text
  const parsed = parseTextAndMRZ(rawText, docSide);

  // display
  let out = '---- EXTRAHIERTE FELDER ----\n';
  for(const k of Object.keys(parsed)){
    out += `${k}: ${parsed[k]}\n`;
  }
  out += '\n---- ROH-TEXT (AUSZUG) ----\n' + (rawText.slice(0,200) + (rawText.length>200 ? '\n...':'' ));
  resultEl.textContent = out;
  status('Fertig.');

  isProcessing=false;
}

// ---- Parser that handles MRZ and front fields ----
function parseTextAndMRZ(rawText, docSide){
  const lines = rawText.split(/\r?\n/).map(l=>l.trim()).filter(Boolean);
  const out = {};
  if(docSide === 'back'){
    const mrz = detectMRZLines(rawText);
    if(mrz.length >= 2){
      out['MRZ1'] = mrz[0];
      out['MRZ2'] = mrz[1];
      // try parse MRZ2 for DOB & expiry (YYMMDD formats)
      try {
        const mrz2 = mrz[1].replace(/ /g,'');
        // DOB pos 7-12, expiry pos 13-18 (depends on format)
        const dobRaw = mrz2.substring(7,13);
        const expRaw = mrz2.substring(13,19);
        out['MRZ Geburtsdatum (raw)'] = dobRaw;
        out['MRZ Ablaufdatum (raw)'] = expRaw;
        // checks
        out['DOB Prüfziffer OK'] = mrzChecksum(mrz2.substring(7,14)) ? 'OK' : 'FAIL';
        out['Expiry Prüfziffer OK'] = mrzChecksum(mrz2.substring(13,20)) ? 'OK' : 'FAIL';
      } catch(e){}
    } else {
      out['MRZ'] = 'Nicht gefunden';
      // try to find address (PLZ + Ort)
      const addr = lines.find(l => /\b\d{5}\b/.test(l));
      if(addr) out['Adresse (gefunden)'] = addr;
    }
  } else {
    // FRONT: DOB, Gültig bis, DocNr
    // search patterns flexible
    const joined = rawText.replace(/\s{2,}/g,' ');
    let m;
    m = joined.match(/(Geburtsdatum|Geb\. Datum|Date of Birth|DOB)[\s:.-]*([0-3]?\d[.\-/]\d{1,2}[.\-/]\d{4})/i);
    if(m) out['Geburtsdatum'] = m[2];
    else {
      m = joined.match(/\b([0-3]?\d[.\-/]\d{1,2}[.\-/]\d{4})\b/);
      if(m) out['Geburtsdatum (fallback)'] = m[1];
    }
    m = joined.match(/(Gültig bis|Gultig bis|Expires|Expiry)[\s:.-]*([0-3]?\d[.\-/]\d{1,2}[.\-/]\d{4})/i);
    if(m) out['Gültig bis'] = m[2];
    // Document number common patterns
    m = joined.match(/(Dok(ument)?nummer|Document No|Doc Nr|Ausweis[-\s]?Nr|ID No|ID)[\s:.-]*([A-Z0-9]{6,18})/i);
    if(m) out['Dokumentnummer'] = m[3];
    else {
      // fallback: look for 8-12 alnum tokens in early lines
      const early = lines.slice(0,6).join(' ');
      const f = early.match(/\b([A-Z0-9]{8,15})\b/);
      if(f) out['Dokumentnummer (fallback)'] = f[1];
    }
  }
  return out;
}

// ---- Auto capture: listen frames and try to auto-run when stable ----
let autoInterval = null;
function startAutoCapture(){
  if(autoInterval) return;
  autoInterval = setInterval(()=>{
    // take overlay crop small temp, preprocess, compute stability
    const {x,y,w,h} = getOverlayCropRect();
    if(!w||!h) return;
    const tmp = document.createElement('canvas'); tmp.width = w; tmp.height = h;
    drawToCanvasFromVideo(tmp, x,y,w,h);
    // use preprocess to normalize size
    const prep = preprocessForOCR(tmp, 800);
    // compute gray + diff
    const g = getGrayFromCanvas(prep);
    const diff = frameDiff(prevGray, g);
    prevGray = g;
    if(diff < DIFF_LIMIT){
      stableFrames++;
    } else stableFrames=0;
    // if stable enough, trigger scan
    if(stableFrames >= STABLE_THRESHOLD){
      runScan(true);
      stableFrames = 0;
    }
  }, 400);
}
function stopAutoCapture(){ if(autoInterval){ clearInterval(autoInterval); autoInterval=null; } }

// ---- Wire UI ----
scanBtn.addEventListener('click', ()=>runScan(false));
flashBtn.addEventListener('click', async ()=>{
  if(!track) return;
  try {
    flashOn = !flashOn;
    await track.applyConstraints({advanced:[{torch:flashOn}]});
    flashBtn.classList.toggle('active',flashOn);
  } catch(e){
    status('Blitz nicht verfügbar: ' + e.message);
  }
});
doctypeSel.addEventListener('change', ()=>{ clearResult(); updateOverlay(); });
sideSel.addEventListener('change', ()=>{ clearResult(); updateOverlay(); });

// overlay update for guidance
function updateOverlay(){
  // adjust overlay proportions slightly based on doc type & side
  if(doctypeSel.value==='aufenth'){
    if(sideSel.value==='front'){ overlay.style.width='84%'; overlay.style.height='48%'; overlay.style.top='50%'; overlay.style.left='50%'; overlay.style.transform='translate(-50%,-50%)'; }
    else { overlay.style.width='86%'; overlay.style.height='52%'; overlay.style.top='55%'; overlay.style.left='50%'; overlay.style.transform='translate(-50%,-50%)'; }
  } else {
    if(sideSel.value==='front'){ overlay.style.width='82%'; overlay.style.height='50%'; overlay.style.top='50%'; overlay.style.left='50%'; overlay.style.transform='translate(-50%,-50%)'; }
    else { overlay.style.width='84%'; overlay.style.height='50%'; overlay.style.top='55%'; overlay.style.left='50%'; overlay.style.transform='translate(-50%,-50%)'; }
  }
}
function clearResult(){ resultEl.textContent=''; status(''); }

updateOverlay();
await startCamera();
await initWorker();
// start auto-capture (optional, you can remove if undesired)
startAutoCapture();

})(); // IIFE end
</script>
</body>
</html>
